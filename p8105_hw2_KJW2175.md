p8105_hw2_KJW2175
================
Kennedy Wade
2025-09-26

# Problem 1

### Cleaning the csv, breaking up, removing, and replacing variables

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.2     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(janitor)
```

    ## 
    ## Attaching package: 'janitor'
    ## 
    ## The following objects are masked from 'package:stats':
    ## 
    ##     chisq.test, fisher.test

``` r
library(readxl)
library(dplyr)
library(forcats)
library(lubridate)
library(stringr)
library(tibble)
library(tidyr)
```

``` r
pols_df <-
    read_csv("./hw2data/pols-month.csv", na = c("NA", ".", "")) |>
    janitor::clean_names() |>
    separate(mon,
    into = c("year", "month", "day"), 
    sep = "-") |>
  
    mutate(month = case_match(
      month, 
      "01" ~ "January", 
      "02" ~ "February",
      "03" ~ "March",
      "04" ~ "April",
      "05" ~ "May",
      "06" ~ "June",
      "07" ~ "July",
      "08" ~ "August", 
      "09" ~ "September",
      "10" ~ "October",
      "11" ~ "November",
      "12" ~ "December" 
    ),
  president = case_match(
    prez_gop,
    1 ~ "gop",
    .default = case_match(prez_dem, 1 ~ "dem")
  ))|> 
  
  arrange (desc(year)) |>
  select(-prez_dem, -prez_gop, -day)
```

    ## Rows: 822 Columns: 9
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl  (8): prez_gop, gov_gop, sen_gop, rep_gop, prez_dem, gov_dem, sen_dem, r...
    ## date (1): mon
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### Cleaning snp.csv data

``` r
snp_df <-
    read_csv("./hw2data/snp.csv", na = c("NA", ".", "")) |>
    janitor::clean_names() |>
    separate(date,
    into = c("month", "day", "year"), 
    sep = "/"
  ) |>
    mutate(month = case_match(
      month, 
      "1" ~ "Jan", 
      "2" ~ "Feb",
      "3" ~ "Mar",
      "4" ~ "Apr",
      "5" ~ "May",
      "6" ~ "Jun",
      "7" ~ "Jul",
      "8" ~ "Aug", 
      "9" ~ "Sept",
      "10" ~ "Oct",
      "11" ~ "Nov",
      "12" ~ "Dec" 
    )) |>
    mutate(year = as.numeric(year),
    year=ifelse(year<=15, year+2000, year+1900),
    year=as.character(year)) |>
  select(year, month, everything(), - day)
```

    ## Rows: 787 Columns: 2
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (1): date
    ## dbl (1): close
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### Tidying the employment data

``` r
unemployment_df <-
    read_csv("./hw2data/unemployment.csv", na = c("NA", ".", "")) |>
    janitor::clean_names() |>
    pivot_longer(
      jan:dec,
      names_to = "month",
      values_to  = "percent_unemployed") |> 
  
  select (year, month,percent_unemployed) |> 
     arrange(desc(year)) |>
  mutate(year = as.character(year))
```

    ## Rows: 68 Columns: 13
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (13): Year, Jan, Feb, Mar, Apr, May, Jun, Jul, Aug, Sep, Oct, Nov, Dec
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### Joining the datasets by merging snp into pols, and merging unemployment into the result.

``` r
final_df =
  left_join(pols_df, snp_df, by = c("year", "month")) |>
  left_join(unemployment_df, by = c("year", "month"))
```

The analysis used three datasets.The `pols_df` dataset, the `snp_df`
dataset, and the `unemployment_df` dataset. The political dataset
contained monthly information about presidential party affiliation, with
columns for `year`, `month`,
`gov_gop`,`sen_dem`,`rep_gop`,`gov_dem`,`sen_dem`,`rep_dem,` and
`president`.The snp dataset recorded monthly stock market values, with
columns for `year`, `month`, and `close`. The unemployment dataset
reported monthly unemployment rates for each year, with columns for
`year`, `month`, and `percent_unemployed`. After cleaning and merging
these datasets, the resulting dataset contains 822 rows and 11 columns,
spanning the years 1947 to 2015 .Variables in the final dataset include
`year`, `month`,
`gov_gop`,`sen_dem`,`rep_gop`,`gov_dem`,`sen_dem`,`rep_dem,`
`president`,`percent_unemployed`, and `close`

# Problem 2

### Specifying the sheet in the Excel file, omitting non-data entries using arguments in read_excel,using reasonable variable names, omitting rows that do not include dumpster-specific data,rounding the number of sports balls to the nearest integer,converting the result to an integer variable (using as.integer)

``` r
mr_trash_df <-
  read_excel("./hw2data/202509 Trash Wheel collection Data.xlsx", sheet = 1, range ="A2:N709") |>
  janitor::clean_names() |>
  mutate(sports_balls = as.integer(sports_balls)) |>
  mutate(service = "mr_trash_wheel") |>
  mutate(year = as.numeric(year))

prof_trash_df <-
  read_excel("./hw2data/202509 Trash Wheel collection Data.xlsx", sheet = 2, range ="A2:M134") |>
janitor::clean_names() |>
mutate(service = "prof_trash_wheel") |>
mutate(year = as.numeric(year))

gwyn_trash_df <-
  read_excel("./hw2data/202509 Trash Wheel Collection Data.xlsx", sheet = 4, range = "A2:L351") |>
  janitor::clean_names() |>
  mutate(service = "gwyn_trash_wheel") |>
  mutate(year = as.numeric(year))

combined_trash_df <- 
  full_join(mr_trash_df, prof_trash_df) |>
  full_join(gwyn_trash_df) |>
  arrange(desc(year))
```

    ## Joining with `by = join_by(dumpster, month, year, date, weight_tons,
    ## volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
    ## glass_bottles, plastic_bags, wrappers, homes_powered, service)`
    ## Joining with `by = join_by(dumpster, month, year, date, weight_tons,
    ## volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts,
    ## plastic_bags, wrappers, homes_powered, service)`

## Finding the total weight of trash collected by Professor Trash Wheel and the total number of cigarette butts collected by Gwynnda in June of 2022.

``` r
print(
  filter(combined_trash_df, service == "prof_trash_wheel") |>
    summarise(total_weight = sum(weight_tons))
)
```

    ## # A tibble: 1 × 1
    ##   total_weight
    ##          <dbl>
    ## 1         282.

``` r
print(
  filter(combined_trash_df, service == "gwyn_trash_wheel", month == "June", year == 2022) |>
    summarise(total_cig_butts = sum(cigarette_butts))
)
```

    ## # A tibble: 1 × 1
    ##   total_cig_butts
    ##             <dbl>
    ## 1           18120

The `combined_trash_df` dataset contains 1,188 records of trash
collection. Key variables include `dumpster`, `month`, `year`, `date`,
`weight_tons`, `volume_cubic_yards`, `plastic_bottles`, `polystyrene`,
`cigarette_butts`, `glass_bottles`, `plastic_bags`, `wrappers`,
`sports_balls`, `homes_powered`, and \`service. Across the recorded
period, Professor Trash Wheel collected a total of 282.26 tons of trash.
In June 2022, Gwynnda collected a total of 18,120 cigarette butts.

# Problem 3

### Pivoting the monthly columns into long format, splitting the date string into year, month, day, and cleaning column names and dropping unnecessary columns

``` r
zillow_df <-
  read_csv('hw2data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv', na = c("NA", ".", "")) |>
  janitor::clean_names() |>
  pivot_longer(
    x2015_01_31:x2024_08_31,
    names_to = "file_date", 
    values_to = "obs_rent"
  ) |>
  separate(file_date, 
    into = c("year", "month", "day"),
    sep = "_"
  ) |>   
  rename("zip_code" = "region_name") |>
  rename("county" = "county_name") |>
  mutate(county = str_replace(county, " County$", "")) |>
  mutate(year = str_replace(year, "^x", "")) |>
  mutate(year = as.numeric(year)) |>
  select(-region_type, -state_name)
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### Entering zip code data

``` r
zip_codes_df <-
  read_csv('hw2data/Zip Codes.csv', na = c("NA", ".", "")) |>
  janitor::clean_names() |>
    separate(file_date, 
    into = c("month", "day", "year"),
    sep = "/"
  ) |>
  mutate(year = as.numeric(year)) |>
  mutate(year = year + 2000) |>
  rename("state" = "state_fips") |>
  mutate(state = "NY") |>
  select(zip_code, neighborhood)
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

### Combinging the zillow_df and the zip_codes_df and inding the total observations that exist

``` r
zillow_zip_codes_df <-
  left_join(zillow_df, zip_codes_df, by = "zip_code") |>
  arrange(desc(year)) |>
  select(year, month, day, obs_rent, neighborhood, county, city, state, zip_code, everything())
```

    ## Warning in left_join(zillow_df, zip_codes_df, by = "zip_code"): Detected an unexpected many-to-many relationship between `x` and `y`.
    ## ℹ Row 4757 of `x` matches multiple rows in `y`.
    ## ℹ Row 256 of `y` matches multiple rows in `x`.
    ## ℹ If a many-to-many relationship is expected, set `relationship =
    ##   "many-to-many"` to silence this warning.

The combined dataset `zillow_zip_codes`has 7,516 observations and 12
variables.

### Finding how many unique ZIP codes are included and how many unique neighborhoods

``` r
zillow_zip_codes_df |>
  pull(zip_code) |>
  unique() |>
  length() 
```

    ## [1] 149

``` r
zillow_zip_codes_df |>
  pull(neighborhood) |>
  unique() |>
  length()
```

    ## [1] 43

The combined dataset `zillow_zip_codes` has 7,516 observations and 12
variables.There are 149 unique zip codes and 43 unique neighborhoods

### Finding which ZIP codes appear in the ZIP code dataset but not in the Zillow Rental Price dataset

``` r
missing_zips <- zip_codes_df |> 
  anti_join(zillow_df, by = "zip_code") |> 
  pull(zip_code) |>
  unique()

print(missing_zips)
```

    ##   [1] 10464 10474 10475 10499 10550 10704 10705 10803 11202 11224 11239 11241
    ##  [13] 11242 11243 11245 11247 11251 11252 11256 10008 10020 10041 10043 10045
    ##  [25] 10047 10048 10055 10072 10080 10081 10082 10087 10101 10102 10103 10104
    ##  [37] 10105 10106 10107 10108 10109 10110 10111 10112 10113 10114 10115 10116
    ##  [49] 10117 10118 10119 10120 10121 10122 10123 10124 10125 10126 10129 10130
    ##  [61] 10131 10132 10133 10138 10149 10150 10151 10152 10153 10154 10155 10156
    ##  [73] 10157 10158 10159 10160 10161 10163 10164 10165 10166 10167 10168 10169
    ##  [85] 10170 10171 10172 10173 10174 10175 10176 10177 10178 10179 10185 10197
    ##  [97] 10199 10213 10242 10249 10256 10259 10260 10261 10265 10268 10269 10270
    ## [109] 10271 10272 10273 10274 10275 10276 10277 10278 10279 10281 10285 10286
    ## [121] 10292 11001 11004 11005 11040 11096 11351 11352 11359 11362 11363 11371
    ## [133] 11380 11381 11386 11405 11411 11412 11413 11414 11416 11417 11419 11420
    ## [145] 11421 11422 11423 11424 11425 11427 11428 11429 11430 11431 11433 11436
    ## [157] 11439 11451 11499 11559 11580 11690 11694 11695 11697 10302 10307 10309
    ## [169] 10310 10311 10313

These ZIP codes could be excluded from the Zillow dataset because they
are P.O. boxes or predominantly commercial areas.

### Making a table that shows the 10 ZIP codes (along with the borough and neighborhood) with largest drop in price from January 2020 to 2021.

``` r
price_data <- zillow_zip_codes_df |>
  filter(year %in% c(2020, 2021) & month == "01") |>
  pivot_wider(
    c("zip_code", "county", "neighborhood"), 
    names_from = year,                           
    values_from = obs_rent,                      
    names_prefix = "price_",
    values_fn = mean 
  ) |>
  mutate(across(starts_with("price_"), as.numeric)) 
```

    ## Warning: Specifying the `id_cols` argument by position was deprecated in tidyr 1.3.0.
    ## ℹ Please explicitly name `id_cols`, like `id_cols = c("zip_code", "county",
    ##   "neighborhood")`.
    ## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was
    ## generated.

``` r
top_drop_tab <- price_data |>
  mutate(price_drop = price_2020 - price_2021) |>
  filter(!is.na(price_drop)) |>
  arrange(desc(price_drop)) |>
  head(10) |>
  select(
    zip_code, 
    county, 
    neighborhood, 
    price_Jan_2020 = price_2020, 
    price_Jan_2021 = price_2021, 
    price_drop
  )

print(top_drop_tab)
```

    ## # A tibble: 10 × 6
    ##    zip_code county   neighborhood       price_Jan_2020 price_Jan_2021 price_drop
    ##       <dbl> <chr>    <chr>                       <dbl>          <dbl>      <dbl>
    ##  1    10007 New York Lower Manhattan             6334.          5422.       913.
    ##  2    10069 New York <NA>                        4623.          3875.       748.
    ##  3    10009 New York Lower East Side             3406.          2692.       714.
    ##  4    10016 New York Gramercy Park and…          3731.          3019.       712.
    ##  5    10001 New York Chelsea and Clint…          4108.          3398.       710.
    ##  6    10002 New York Lower East Side             3645.          2935.       710.
    ##  7    10004 New York Lower Manhattan             3150.          2444.       706.
    ##  8    10038 New York Lower Manhattan             3573.          2876.       698.
    ##  9    10012 New York Greenwich Village…          3629.          2942.       686.
    ## 10    10010 New York Gramercy Park and…          3697.          3012.       685.

The table shows that several ZIP codes in Manhattan experienced the
largest declines in rental prices during the COVID-19 pandemic. Areas
like Lower Manhattan, Gramercy Park, and the Lower East Side were
particularly affected. These declines may be due to factors like the
switch to remote work, reduced demand for downtown housing, and changing
rental patterns during the pandemic.
